{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nTGCMKSzVXtF"
   },
   "source": [
    "# Notebook\n",
    "## Sistem Rekomendasi Obat berdasarkan _Weighted Hybrid Approach_\n",
    "\n",
    "Notebook ini menyajikan penerapan dan eksperimentasi _weighted hybrid approach_ pada sistem rekomendasi obat. _Weighted hybrid approach_ yang diusulkan merupakan kombinasi antara .... dan .... . Beberapa teknik pembobotan yang akan dimasukkan dalam eksperimentasi antara lain ...., ...., dan ....."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XIftJR9dUmmb"
   },
   "source": [
    "## 1. Pustaka\n",
    "\n",
    "Impor pustaka yang dibutuhkan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ejBtEAGbKzpI"
   },
   "outputs": [],
   "source": [
    "# pustaka eksternal\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import xgboost as xgb\n",
    "\n",
    "# pustaka custom\n",
    "from analysis import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h3_BPWQqX9mt"
   },
   "source": [
    "## 2. Persiapan Set Data\n",
    "\n",
    "Pada bagian ini, dilakukan persiapan set data yang dibutuhkan dalam penelitian. Karena set data yang sesuai untuk secara langsung digunakan dalam penelitian ini belum tersedia saat penelitian ini dikerjakan, maka Peneliti melakukan pengumpulan data dari beberapa sumber dan menggabungkannya.\n",
    "\n",
    "Set data `WebMD` dan `DailyMed` digabungkan dalam struktur data DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OBNcD-4TKzpT",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# berkas WebMD Drug Reviews oleh Rohan Harode dari Kaggle\n",
    "path_wmd = \"data/webmd/webmd.csv\"\n",
    "\n",
    "# berkas DailyMed Drug dari situs web DailyMed\n",
    "# yang dikompilasi dengan menggunakan generate_dailymed.py\n",
    "path_dm = \"data/dailymed/dailymed.csv\"\n",
    "\n",
    "df_wmd = pd.read_csv(path_wmd)\n",
    "df_dm = pd.read_csv(path_dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Atribut yang diperlukan sebagai pelengkap data pada DailyMed, antara lain:\n",
    "1. nama obat secara umum pada kolom `sub_name`\n",
    "2. daftar bahan aktif pada kolom `list_activeIngredient`, dan \n",
    "3. daftar bahan inaktif pada kolom `list_activeIngredient`.\n",
    "\n",
    "Oleh karena itu, perlu dilakukan seleksi kolom pada DataFrame `df_dm` sebagai berikut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dm = df_dm[[\"SubName\", \"ListActiveIngredient\", \"ListInactiveIngredient\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gabungkan DataFrame DailyMed `df_dm` dan DataFrame MebMD `df_wmd` dengan menggunakan kolom `sub_name` di `df_dm` dan kolom `Drug` di `df_wmd` sebagai indeks pengabungan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_drugs = pd.merge(df_dm, df_wmd, left_on = \"SubName\", right_on = \"Drug\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Analisis Data\n",
    "\n",
    "Dalam penelitian ini, analisis dilakukan pada `df_drugs` untuk memahami tipe data dan mengidentifikasi kesalahan. Informasi tersebut digunakan untuk menentukan prosedur yang sesuai dalam tahap prapemrosesan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kita mulai dengan menghitung jumlah masing-masing nilai yang berbeda pada kolom `Drug` untuk mengetahui jumlah baris data untuk setiap obat. Informasi ini diperlukan untuk memastikan kecukupan data penelitian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_drugs[\"Drug\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pada sel tersebut, kita dapat melihat bahwa ada 74 nama obat dalam `df_drugs`. Obat dengan baris data terbanyak adalah `lisinopril` (12.807), sementara obat dengan baris data tersedikit adalah `cromolyn sodium`, `caffeine citrate`, dan `bexarotene` (2).\n",
    "\n",
    "Jika menggunakan 500 baris data sebagai ambang batas kecukupan data, maka persentase jumlah obat disajikan sebagai berikut."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tipe data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_drugs.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Untuk memeriksa tipe data dari masing2 varibael/kolom/fitur dengan menggunakan .dtypes. untuk dtype (object) pada pandas digunakan untuk tipe data Teks atau campuran nilai numerik dan non-numeric. untuk dtype (int64) pada pandas digunakan untuk tipe data Integer numbers. Pada sel diatas, kita dapat melihat bahwa 2 jenis type data yang muncul yaitu object dan int64."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for col in df_drugs:\n",
    "    drugs = pd.get_dummies(df_drugs[col],prefix='', prefix_sep='').sum() \n",
    "    print(col, \":\", drugs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pada sel diatas, kita dapat melihat rentang nilai dari setiap atribut. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|     Nama attribut      |      Tipe Attribut     |                Rentang Nilai                                    |\n",
    "| ---------------------- | -----------------------| ----------------------------------------------------------------|\n",
    "|      SubName           |        Nominal         |  acarbose, acetazolamide , aripiprazole, baclofen, benzonatate,...,valproic acid, voriconazole, zaleplon, zolmitriptan, zolmitriptan, zonisamide   |\n",
    "| ListActiveIngredient   |        Nominal         |  ACARBOSE 25 mg -1-1, ACETAZOLAMIDE 125 mg -1-1, ACETAZOLAMIDE 250 mg -1-1, ACETAZOLAMIDE 500 mg -1-1, ARIPIPRAZOLE1 mg 1mL, ...,valproic acid 250 mg -1-1 |\n",
    "| ListInactiveIngredient |        Nominal         |  ACETIC ACID, SODIUM CHLORIDE, SODIUM ACETATE, WATER, ALCOHOL, ANHYDROUS CITRIC ACID, ... sodium hydroxide, hydrochloric acid|\n",
    "|       Age              |        Nominal         |  0-2, 13-18, 19-24, 25-34, 3-6, 35-44, 45-54, 55-64, 65-74, 7-12, 75 or over|\n",
    "|     Condition          |        Nominal         |  \"Change of Life\" Signs, A Condition of Bladder Dysfunction from Nerve Disorder , A Condition of Bladder Dysfunction from Nerve Disorder, ..., infection caused by bacteria    |\n",
    "|     Date               |        Nominal         | 1/1/2008, 1/1/2009, 1/1/2011, 1/1/2012, ..., 9/9/2013 9/9/2017         |\n",
    "|     Drug               |        Nominal         | acarbose, acetazolamide, aripiprazole, baclofen, benzonatate, ... zonisamide |\n",
    "|     DrugId             |        Nominal         | 676, 911, 1027, 1049, 1636, ... ,93290,  94574, 148989,  149812  |\n",
    "|     EaseofUse          |       Ordinal          |  1, 2, 3, 4, 5                                                   |\n",
    "|     Effectiveness      |       Ordinal          |  1, 2, 3, 4, 5                                                   |\n",
    "|    Reviews             |       Nominal          |  an this drug be taken on a long term bases? I had a cough for years that I dr with and nothing worked. I was told it can not be taken long term. What is the side effects if taken long term, ......   a 90 day supply of Lisinopril 10 mg which averages $3.33 per month. |\n",
    "|     Satisfaction       |       Ordinal          |  1, 2, 3, 4, 5                                                   |\n",
    "|     Sex                |       Binary           |  Female, Male                                                    |\n",
    "|     Sides              |       Nominal          |  Constipation ,  nausea ,  headache ,  diarrhea ,  vomiting ,  stomach  upset, gas, tremor,  dizziness , drowsiness, or  trouble sleeping  may occur, ... Upset stomach ,  nausea ,  vomiting , gas, or  diarrhea  may occur |\n",
    "|     UsefulCount        |       Ordinal          |  0, 1, 2, 3, 4...... 140                                          |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mengidentifikasi Kesalahan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_drugs.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dalam mengidentifikasi kesalahahan dapat dilakukan agregasi data menggunakan fungsi sum(). Berdasarkan analisis diatas dapat dilihat bahwa dalam dataset tersebut hanya ada satu atribut yang memiliki nilai kosong atau NULL sebanyak 16 missing value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "s = pd.get_dummies(df_drugs['SubName'],prefix='', prefix_sep='').sum() \n",
    "item_counts = df_drugs[\"SubName\"].value_counts()\n",
    "for i in item_counts.items():\n",
    "    print(i) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Untuk kolom atribut sub_name tidak ada nilai aneh atau ganjil serta tidak ditemukan nilai yang kosong pada field sub_name "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.get_dummies(df_drugs['ListActiveIngredient'],prefix='', prefix_sep='').sum() \n",
    "item_counts = df_drugs[\"ListActiveIngredient\"].value_counts()\n",
    "for i in item_counts.items():\n",
    "    print(i) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Untuk kolom atribut list_activeIngredient tidak ada nilai aneh atau ganjil serta tidak ditemukan nilai yang kosong pada field list_activeIngredient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.get_dummies(df_drugs['ListInactiveIngredient'],prefix='', prefix_sep='').sum() \n",
    "item_counts = df_drugs[\"ListInactiveIngredient\"].value_counts()\n",
    "for i in item_counts.items():\n",
    "    print(i) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Untuk kolom atribut ListInactiveIngredient tidak ada nilai aneh atau ganjil serta tidak ditemukan nilai yang kosong pada field ListInactiveIngredient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "s = pd.get_dummies(df_drugs['Age'],prefix='', prefix_sep='').sum() \n",
    "item_counts = df_drugs[\"Age\"].value_counts()\n",
    "for i in item_counts.items():\n",
    "    print(i) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Untuk kolom atribut 'Age' terdapat nilai kosong atau missing value sebanyak 1941 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.get_dummies(df_drugs['Condition'],prefix='', prefix_sep='').sum() \n",
    "item_counts = df_drugs[\"Condition\"].value_counts()\n",
    "for i in item_counts.items():\n",
    "    print(i) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Untuk kolom atribut Condition tidak ada nilai aneh atau ganjil serta tidak ditemukan nilai yang kosong pada field 'Condition'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.get_dummies(df_drugs['Date'],prefix='', prefix_sep='').sum() \n",
    "item_counts = df_drugs[\"Date\"].value_counts()\n",
    "for i in item_counts.items():\n",
    "    print(i) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Untuk kolom atribut 'Date' tidak ada nilai aneh atau ganjil serta tidak ditemukan nilai yang kosong pada field 'Date'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "s = pd.get_dummies(df_drugs['Drug'],prefix='', prefix_sep='').sum() \n",
    "item_counts = df_drugs[\"Drug\"].value_counts()\n",
    "for i in item_counts.items():\n",
    "    print(i) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Untuk kolom atribut 'Drug' tidak ada nilai aneh atau ganjil serta tidak ditemukan nilai yang kosong pada field 'Drug'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.get_dummies(df_drugs['EaseofUse'],prefix='', prefix_sep='').sum() \n",
    "item_counts = df_drugs[\"EaseofUse\"].value_counts()\n",
    "for i in item_counts.items():\n",
    "    print(i) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Untuk kolom atribut 'EaseofUse' tidak ada nilai aneh atau ganjil serta tidak ditemukan nilai yang kosong pada field 'EaseofUse'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.get_dummies(df_drugs['Effectiveness'],prefix='', prefix_sep='').sum() \n",
    "item_counts = df_drugs[\"Effectiveness\"].value_counts()\n",
    "for i in item_counts.items():\n",
    "    print(i) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Untuk kolom atribut 'Effectiveness' tidak ada nilai aneh atau ganjil serta tidak ditemukan nilai yang kosong pada field 'Effectiveness'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.get_dummies(df_drugs['Satisfaction'],prefix='', prefix_sep='').sum() \n",
    "item_counts = df_drugs[\"Satisfaction\"].value_counts()\n",
    "for i in item_counts.items():\n",
    "    print(i) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Untuk kolom atribut 'Satisfaction' tidak ada nilai aneh atau ganjil serta tidak ditemukan nilai yang kosong pada field 'Satisfaction'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.get_dummies(df_drugs['Sex'],prefix='', prefix_sep='').sum() \n",
    "item_counts = df_drugs[\"Sex\"].value_counts()\n",
    "for i in item_counts.items():\n",
    "    print(i) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Untuk kolom atribut 'Sex' terdapat nilai kosong atau missing value sebanyak 4349"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "s = pd.get_dummies(df_drugs['Sides'],prefix='', prefix_sep='').sum() \n",
    "item_counts = df_drugs[\"Sides\"].value_counts()\n",
    "for i in item_counts.items():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Untuk kolom atribut 'Sides' tidak ada nilai aneh atau ganjil serta tidak ditemukan nilai yang kosong pada field 'Sides'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "s = pd.get_dummies(df_drugs['UsefulCount'],prefix='', prefix_sep='').sum() \n",
    "item_counts = df_drugs[\"UsefulCount\"].value_counts()\n",
    "for i in item_counts.items():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Untuk kolom atribut 'UsefulCount' tidak ada nilai aneh atau ganjil serta tidak ditemukan nilai yang kosong pada field 'UsefulCount'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = df_drugs.drop(columns = ['Reviews'])\n",
    "for col in data1:\n",
    "    s = pd.get_dummies(df_drugs[col],prefix='', prefix_sep='').sum() \n",
    "    print(col, \":\", s)\n",
    "\n",
    "# s = pd.get_dummies(data1,prefix='', prefix_sep='').sum().sort()\n",
    "# s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_sufficient = sum(x >= 500 for x in df_drugs[\"Drug\"].value_counts())\n",
    "n_insufficient = sum(x < 500 for x in df_drugs[\"Drug\"].value_counts())\n",
    "print(\"Cukup\", n_sufficient, \"dan\", \"Tidak Cukup:\", n_insufficient)\n",
    "# fig = go.Figure(data=[go.Pie(labels=[\"Cukup\", \"Tidak Cukup\"],\n",
    "#                              values=[n_sufficient, n_insufficient], hole = 0.5)])\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Memperhatikan persentase tersebut, maka diperlukan penambahan lebih banyak baris data untuk setiap obat dengan total baris data yang kurang dari 500. Untuk saat ini, kita cukup gunakan baris data obat yang cukup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_sufficient = [val for val, cnt in df_drugs[\"Drug\"].value_counts().iteritems() if cnt >= 500]\n",
    "df_drugs_sub = df_drugs[df_drugs[\"Drug\"].isin(list_sufficient)]\n",
    "df_drugs_sub[(df_drugs_sub[\"Age\"] == \" \") & (df_drugs_sub[\"Sex\"] == \" \")].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df_drugs_sub.pivot_table(columns=[\"Sex\", \"Age\", \"Condition\"], aggfunc=\"size\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Periksa banyaknya baris data dengan nilai atribut `Age` dan `Sex` yang kosong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt_empty_agensex = df_drugs_sub[(df_drugs_sub[\"Age\"] == \" \") & (df_drugs_sub[\"Sex\"] == \" \")].shape[0]\n",
    "print(\"Jumlah baris data dengan nilai atribut Age dan Sex yang kosong adalah\", cnt_empty_agensex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Prapemrosesan\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tahap pertama pemrosesan adalah mengubah nilai pada kolom `ListActiveIngredient` ke dalam bentuk _one-hot encoding vector_. _One-hot encoding_ mengubah fitur kategorikal/nominal ke format yang lebih sesuai digunakan dalam algoritma klasifikasi dan regresi. Dalam sistem rekomendasi ini, algoritma klasifikasi digunakan sebagai pembentuk model _hybrid_. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def active_ingredient_text_cleaning(txt_in):\n",
    "    txt_out = txt_in.replace(\"[[\", \"\")\n",
    "    txt_out = txt_out.replace(\"]]\", \"\")\n",
    "    list_out = txt_out.split(\"], [\")\n",
    "    list_out = [[j.strip(\"\\'\") for j in i.split(\",\")][0].lower() for i in list_out]\n",
    "    return list_out\n",
    "\n",
    "list_active_ingredients = []\n",
    "for i in df_drugs_sub['ListActiveIngredient']:\n",
    "    list_active_ingredients.append(active_ingredient_text_cleaning(i))\n",
    "\n",
    "# hapus kolom list active ingredient\n",
    "df_drugs_sub = df_drugs_sub.drop(columns = [\"ListActiveIngredient\"])\n",
    "# buat kolom active ingredients berdasarkan list active ingredients\n",
    "df_drugs_sub[\"ActiveIngredients\"] = list_active_ingredients\n",
    "\n",
    "# # one-hot encoding\n",
    "# mlb = MultiLabelBinarizer()\n",
    "# df_drugs_sub = df_drugs_sub.join(pd.DataFrame(mlb.fit_transform(df_drugs_sub.pop(\"ActiveIngredients\")),\n",
    "#                                               columns=mlb.classes_,\n",
    "#                                               index=df_drugs_sub.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tahap kedua pemrosesan adalah mengubah nilai pada kolom `ListInactiveIngredient` ke dalam bentuk _one-hot encoding vector_, sama seperti pada `ListActiveIngredient`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inactive_ingredient_text_cleaning(txt_in):\n",
    "    txt_out = txt_in.replace(\"[[\", \"\")\n",
    "    txt_out = txt_out.replace(\"]]\", \"\")\n",
    "    list_out = txt_out.split(\"], [\")\n",
    "    list_out = [[j.strip(\"\\'\") for j in i.split(\",\")][0].lower() for i in list_out]\n",
    "    return list_out\n",
    "\n",
    "list_inactive_ingredients = []\n",
    "for i in df_drugs_sub['ListInactiveIngredient']:\n",
    "    list_inactive_ingredients.append(inactive_ingredient_text_cleaning(i))\n",
    "\n",
    "# hapus kolom list inactive ingredient\n",
    "df_drugs_sub = df_drugs_sub.drop(columns = [\"ListInactiveIngredient\"])\n",
    "# buat kolom inactive ingredients berdasarkan list inactive ingredients\n",
    "df_drugs_sub[\"InactiveIngredients\"] = list_inactive_ingredients\n",
    "\n",
    "# # one-hot encoding\n",
    "# mlb = MultiLabelBinarizer()\n",
    "# df_drugs_sub = df_drugs_sub.join(pd.DataFrame(mlb.fit_transform(df_drugs_sub.pop(\"InactiveIngredients\")),\n",
    "#                                               columns=mlb.classes_,\n",
    "#                                               index=df_drugs_sub.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tahap ketiga pemrosesan adalah mengubah nilai pada kolom `sides` ke dalam bentuk _one-hot encoding vector_, sama seperti pada `ListActiveIngredient` dan `ListInactiveIngredient`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sides_text_cleaning(txt_in):\n",
    "    # ganti whitespace lebih dari 1 menjadi 1 \n",
    "    txt_out = re.sub('\\s+', ' ', txt_in)\n",
    "    # hapus kalimat keterangan\n",
    "    txt_out = txt_out.replace(\"If any of these effects persist or worsen, tell your doctor or pharmacist promptly.\", \"\")\n",
    "    txt_out = txt_out.replace(\"If any of these effects last or get worse, tell your doctor or pharmacist promptly.\", \"\")\n",
    "    txt_out = txt_out.replace(\"may occur, especially during the first 2 hours after you take the medication .\", \"\")\n",
    "    txt_out = txt_out.replace(\"may occur as your body adjusts to this medication .\", \"\")\n",
    "    txt_out = txt_out.replace(\"may occur as your body adjusts to the medication .\", \"\")\n",
    "    txt_out = txt_out.replace(\"may also occur.\", \"\")\n",
    "    txt_out = txt_out.replace(\"may occur.\", \"\")\n",
    "    txt_out = txt_out.replace(\"and \", \"\")\n",
    "    txt_out = txt_out.replace(\"your \", \"\")\n",
    "    txt_out = txt_out.replace(\"or \", \"\")\n",
    "    return txt_out\n",
    "\n",
    "list_sides = []\n",
    "for id, val in df_drugs_sub[\"Sides\"].iteritems():\n",
    "    # pembersihan text sides dan tokenisasi text sides\n",
    "    list_sides.append([i.strip().lower() for i in sides_text_cleaning(val).split(\",\")])\n",
    "\n",
    "# hapus kolom sides yang lama\n",
    "df_drugs_sub = df_drugs_sub.drop(columns = [\"Sides\"])\n",
    "# buat kolom sides yang baru berdasarkan list sides\n",
    "df_drugs_sub[\"Sides\"] = list_sides\n",
    "\n",
    "# # one-hot encoding\n",
    "# mlb = MultiLabelBinarizer()\n",
    "# df_drugs_sub = df_drugs_sub.join(pd.DataFrame(mlb.fit_transform(df_drugs_sub.pop(\"Sides\")),\n",
    "#                                               columns=mlb.classes_,\n",
    "#                                               index=df_drugs_sub.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pada `df_drugs` terdapat 1.051 baris data dengan nilai atribut `Age` dan `Sex` yang kosong. Oleh karena itu, dilakukan imputasi dengan menggunakan Simple Imputer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# label encoding map untuk nilai pada sex\n",
    "map_sex = {\"Male\":0, \"Female\":1}\n",
    "# label encoding map untuk nilai pada age\n",
    "map_age = {'0-2':0,\n",
    "           '3-6':1,\n",
    "           '7-12':2,\n",
    "           '13-18':3,\n",
    "           '19-24':4,\n",
    "           '25-34':5,\n",
    "           '35-44':6,\n",
    "           '45-54':7,\n",
    "           '55-64':8,\n",
    "           '65-74':9,\n",
    "           '75 or over':10}\n",
    "\n",
    "df_tmp = df_drugs_sub.copy()\n",
    "# label encoding pada sex\n",
    "df_tmp[\"Sexmap\"] = df_tmp[\"Sex\"].map(map_sex)\n",
    "# label encoding pada age\n",
    "df_tmp[\"Agemap\"] = df_tmp[\"Age\"].map(map_age)\n",
    "\n",
    "# inverted label encoding map untuk nilai pada sex\n",
    "inv_map_sex = {v: k for k, v in map_sex.items()}\n",
    "# inverted label encoding map untuk nilai pada age\n",
    "inv_map_age = {v: k for k, v in map_age.items()}\n",
    "\n",
    "# penanganan missing values pada sex dan age\n",
    "# imp = KNNImputer(n_neighbors=1)\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy=\"most_frequent\")\n",
    "mat = imp.fit_transform(df_tmp[[\"Agemap\", \"Sexmap\", \"Satisfaction\"]])\n",
    "df_tmp2 = pd.DataFrame(mat, columns=[\"NewAge\", \"NewSex\", \"NewSatisfaction\"])\n",
    "df_drugs_sub[\"Sex\"] = df_tmp2[\"NewSex\"].map(inv_map_sex).tolist()\n",
    "df_drugs_sub[\"Age\"] = df_tmp2[\"NewAge\"].map(inv_map_age).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pembagian set data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Untuk menerapkan _item-based collaborative filtering_ pada sistem rekomendasi obat, dibutuhkan matriks pengguna/obat. Pada matriks tersebut terdapat _\"user id\"_, _\"drug id\"_, dan _\"drug rating\"_. Ilustrasi matriks tersebut adalah sebagai berikut.\n",
    "\n",
    "|  | drug<sub>1</sub> | drug<sub>2</sub> | drug<sub>3</sub> |\n",
    "| :---: | :---: | :---: | :---: |\n",
    "| user<sub>1</sub> | rating<sub>user<sub>1</sub>,drug<sub>1</sub></sub> | rating<sub>user<sub>1</sub>,drug<sub>2</sub></sub> | rating<sub>user<sub>1</sub>,drug<sub>3</sub></sub> |\n",
    "| user<sub>2</sub> | rating<sub>user<sub>2</sub>,drug<sub>1</sub></sub> | rating<sub>user<sub>2</sub>,drug<sub>2</sub></sub> | rating<sub>user<sub>2</sub>,drug<sub>3</sub></sub> |\n",
    "| user<sub>3</sub> | rating<sub>user<sub>3</sub>,drug<sub>1</sub></sub> | rating<sub>user<sub>3</sub>,drug<sub>2</sub></sub> | rating<sub>user<sub>3</sub>,drug<sub>3</sub></sub> |\n",
    "| user<sub>4</sub> | rating<sub>user<sub>4</sub>,drug<sub>1</sub></sub> | rating<sub>user<sub>4</sub>,drug<sub>2</sub></sub> | rating<sub>user<sub>4</sub>,drug<sub>3</sub></sub> |\n",
    "| user<sub>5</sub> | rating<sub>user<sub>5</sub>,drug<sub>1</sub></sub> | rating<sub>user<sub>5</sub>,drug<sub>2</sub></sub> | rating<sub>user<sub>5</sub>,drug<sub>3</sub></sub> |\n",
    "\n",
    "\n",
    "_\"user id\"_ tidak tersedia dalam `df_drugs`. Oleh karena itu, ....\n",
    "\n",
    "_\"drug id\"_ tersedia dalam `df_drugs`. Oleh karena itu, ....\n",
    "\n",
    "_\"drug rating\"_ tidak tersedia dalam `df_drugs`. Oleh karena itu, ...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Drug\n",
    "df_item = pd.DataFrame({'Drug':df_drugs_sub['Drug'],\n",
    "                        'ActiveIngredients':df_drugs_sub['ActiveIngredients'],\n",
    "                        'InactiveIngredients':df_drugs_sub['InactiveIngredients'],\n",
    "                        'Sides':df_drugs_sub['Sides']})\n",
    "# reset index setiap baris\n",
    "df_item = df_item.reset_index(drop=True)\n",
    "# buat duplikat df_item, yaitu df_tmp\n",
    "df_tmp = df_item.copy()\n",
    "# ubah nilai ActiveIngredients dari list of string menjadi\n",
    "# string untuk memungkinkan fungsi drop_duplicates dijalankan\n",
    "df_tmp['ActiveIngredients'] = [\" \".join(i) for i in df_tmp['ActiveIngredients']]\n",
    "# ubah nilai InactiveIngredients dari list of string menjadi\n",
    "# string untuk memungkinkan fungsi drop_duplicates dijalankan\n",
    "df_tmp['InactiveIngredients'] = [\" \".join(i) for i in df_tmp['InactiveIngredients']]\n",
    "# ubah nilai Sides dari list of string menjadi\n",
    "# string untuk memungkinkan fungsi drop_duplicates dijalankan\n",
    "df_tmp['Sides'] = [\" \".join(i) for i in df_tmp['Sides']]\n",
    "# hapus baris data duplikat pada df_tmp dan simpan index\n",
    "# baris data yang dipertahankan dalam list_index\n",
    "list_index = list(df_tmp.drop_duplicates().index)\n",
    "# gunakan list_index yang didapatkan untuk memfilter\n",
    "# baris data pada df_item\n",
    "df_item = df_item.iloc[list_index]\n",
    "# reset index setiap baris\n",
    "df_item = df_item.reset_index(drop=True)\n",
    "# buat kolom ItemId berdasarkan index setiap baris\n",
    "df_item[\"ItemId\"] = df_item.index + 1\n",
    "# rapikan posisi kolom dengan memindahkan \n",
    "# posisi kolom \"ItemId\" ke kolom pertama\n",
    "df_item = df_item[['ItemId','Drug','ActiveIngredients','InactiveIngredients','Sides']]\n",
    "df_item.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Data User\n",
    "df_user = pd.DataFrame({'Age':df_drugs_sub['Age'],\n",
    "                        'Sex':df_drugs_sub['Sex'],\n",
    "                        'Condition':df_drugs_sub['Condition']})\n",
    "# hapus baris data duplikat pada df_user dan \n",
    "# reset index setiap baris\n",
    "df_user = df_user.drop_duplicates().reset_index(drop=True)\n",
    "# buat kolom UserId berdasarkan index setiap baris\n",
    "df_user[\"UserId\"] = df_user.index + 1\n",
    "# rapikan posisi kolom dengan memindahkan \n",
    "# posisi kolom \"UserId\" ke kolom pertama\n",
    "df_user = df_user[['UserId','Age','Sex','Condition']]\n",
    "df_user.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Data Rating\n",
    "# left outer merge df_drugs_sub dan df_item\n",
    "# berdasarkan kolom Drug\n",
    "df_tmp = df_drugs_sub.merge(df_item,\n",
    "                            how=\"left\",\n",
    "                            on=\"Drug\")\n",
    "# left outer merge df_tmp dan df_user berdasarkan\n",
    "# setiap kolom yang ada pada df_user\n",
    "df_rating = df_tmp.merge(df_user,\n",
    "                         \"left\")\n",
    "# rapikan posisi kolom dengan memindahkan \n",
    "# posisi kolom \"UserId\" dan \"ItemId\"\n",
    "# ke kolom bagian awal df_rating \n",
    "df_rating = df_rating[['UserId',\n",
    "                       'ItemId',\n",
    "                       'EaseofUse',\n",
    "                       'Effectiveness',\n",
    "                       'Satisfaction']]\n",
    "# hapus baris data yang duplikat dan reset index\n",
    "df_rating = df_rating.drop_duplicates().reset_index(drop=True)\n",
    "df_rating.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Pembangunan Model Rekomendasi\n",
    "\n",
    "...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 70% baris data dipilih secara random \n",
    "# sebagai data train dan sisanya sebagai data test\n",
    "df_rating_train = df_rating.sample(frac = 0.7)\n",
    "df_rating_test = df_rating.drop(df_rating_train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = df_rating_train[['UserId', 'ItemId']]\n",
    "y_train = df_rating_train[['Effectiveness']]\n",
    "x_test = df_rating_test[['UserId', 'ItemId']]\n",
    "y_test = df_rating_test['Effectiveness']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# one hot encoding pada kolom Condition\n",
    "one_hot = pd.get_dummies(df_user['Condition'])\n",
    "# hapus kolom Condition karena saat ini sudah di-encode\n",
    "df_user = df_user.drop('Condition', axis = 1)\n",
    "# gabungkan hasil encode ke df_user\n",
    "df_user = df_user.join(one_hot)\n",
    "\n",
    "# one hot encoding pada kolom Sex\n",
    "one_hot = pd.get_dummies(df_user['Sex'])\n",
    "# hapus kolom Sex karena saat ini sudah di-encode\n",
    "df_user = df_user.drop('Sex', axis = 1)\n",
    "# gabungkan hasil encode ke df_user\n",
    "df_user = df_user.join(one_hot)\n",
    "\n",
    "# ordinal label encoding map untuk nilai pada Age\n",
    "map_age = {'0-2':0,\n",
    "           '3-6':1,\n",
    "           '7-12':2,\n",
    "           '13-18':3,\n",
    "           '19-24':4,\n",
    "           '25-34':5,\n",
    "           '35-44':6,\n",
    "           '45-54':7,\n",
    "           '55-64':8,\n",
    "           '65-74':9,\n",
    "           '75 or over':10}\n",
    "df_tmp = df_user.copy()\n",
    "# label encoding pada Age\n",
    "df_user[\"Age\"] = df_tmp[\"Age\"].map(map_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encoding pada kolom ActiveIngredients\n",
    "mlb = MultiLabelBinarizer()\n",
    "df_item = df_item.join(pd.DataFrame(mlb.fit_transform(df_item.pop(\"ActiveIngredients\")),\n",
    "                                    columns=mlb.classes_,\n",
    "                                    index=df_item.index))\n",
    "\n",
    "# one-hot encoding pada kolom InactiveIngredients\n",
    "mlb = MultiLabelBinarizer()\n",
    "df_item = df_item.join(pd.DataFrame(mlb.fit_transform(df_item.pop(\"InactiveIngredients\")),\n",
    "                                    columns=mlb.classes_,\n",
    "                                    index=df_item.index))\n",
    "\n",
    "# one-hot encoding pada kolom Sides\n",
    "mlb = MultiLabelBinarizer()\n",
    "df_item = df_item.join(pd.DataFrame(mlb.fit_transform(df_item.pop(\"Sides\")),\n",
    "                                    columns=mlb.classes_,\n",
    "                                    index=df_item.index))\n",
    "\n",
    "# hapus kolom Drug (id=1), [] (id=23), \" \" (id=100)\n",
    "df_item = df_item.drop(df_item.iloc[:, [1, 23, 100]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge df_item dan df_user untuk masing-masing set data latih dan uji\n",
    "x_train = x_train.join(df_user.set_index('UserId'),\n",
    "                       on = 'UserId').join(df_item.set_index('ItemId'),\n",
    "                                           on = 'ItemId')\n",
    "\n",
    "x_test = x_test.join(df_user.set_index('UserId'),\n",
    "                     on = 'UserId').join(df_item.set_index('ItemId'),\n",
    "                                         on = 'ItemId')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommendation Model Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model 1\n",
    "model1 = xgb.XGBRegressor(objective='reg:squarederror')\n",
    "model1.fit(x_train, y_train)\n",
    "\n",
    "pred1 = model1.predict(x_test)\n",
    "rmse = np.sqrt(np.mean((pred1 - y_test.to_numpy())**2))\n",
    "print(f'content-based rmse = {rmse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_single_prediction(userid, itemid, similarity_mtx, utility):\n",
    "    user_rating = utility.iloc[:,userid-1]\n",
    "    item_similarity = similarity_mtx[itemid-1]\n",
    "    numerate = np.dot(user_rating, item_similarity)\n",
    "    denom = item_similarity[user_rating > 0].sum()\n",
    "            \n",
    "    if denom == 0 or numerate == 0:\n",
    "        return user_rating[user_rating>0].mean()\n",
    "    \n",
    "    return numerate / denom\n",
    "\n",
    "def compute_all_prediction(test_set, pred_func, similarity_mtx, utility, **kwargs):\n",
    "    pred = []\n",
    "    for data in test_set:\n",
    "        res = pred_func(userid = data[0], \n",
    "                        itemid = data[1], \n",
    "                        similarity_mtx = similarity_mtx, \n",
    "                        utility = utility, \n",
    "                        **kwargs)\n",
    "        pred.append(res)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model 2\n",
    "# construct the utility matrix\n",
    "utility = df_rating_train.pivot(index = 'ItemId', columns = 'UserId', values = 'Effectiveness')\n",
    "utility = utility.fillna(0)\n",
    "\n",
    "# calculate the similarity\n",
    "similarity_mtx = 1 - squareform(pdist(utility, 'cosine'))\n",
    "\n",
    "pred2 = compute_all_prediction(df_rating_test[['UserId', 'ItemId']].to_numpy(),\n",
    "                               compute_single_prediction,\n",
    "                               similarity_mtx,\n",
    "                               utility)\n",
    "pred2 = np.array(pred2)\n",
    "\n",
    "rmse = np.sqrt(np.mean((pred2 - y_test.to_numpy())**2))\n",
    "print(f'rmse of item-item collaborative filtering = {rmse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Pengujian Model Rekomendasi\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chart_val = []\n",
    "\n",
    "w = np.linspace(0,1,21)\n",
    "\n",
    "for i in w:\n",
    "    pred4 = pred1*i + pred2*(1-i)\n",
    "    rmse = np.sqrt(np.mean((pred4 - y_test.to_numpy())**2))\n",
    "    chart_val.append([i, rmse])\n",
    "\n",
    "chart_val_np = np.array(chart_val)\n",
    "plt.plot(chart_val_np[:, 0], chart_val_np[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "TA-102.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
